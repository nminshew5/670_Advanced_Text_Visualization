{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing scikit-learn text classification weights\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install lightning-python\n",
    "\n",
    "conda install -c conda-forge sklearn-contrib-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scattertext as st\n",
    "import spacy\n",
    "from pprint import pprint\n",
    "import en_core_web_sm\n",
    "\n",
    "#CSV\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "#pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "#numpy\n",
    "import numpy as np\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "# stopwords, FreqDist, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#regular expression\n",
    "import re\n",
    "\n",
    "#seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "#import packages for scatter text\n",
    "import scattertext as st\n",
    "import spacy\n",
    "from pprint import pprint\n",
    "import en_core_web_sm\n",
    "\n",
    "#SKlearn packages\n",
    "import sklearn\n",
    "from lightning.classification import CDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# feature engineering (words to vectors)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# classification algorithms (or classifiers)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "# build a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# model evaluation, validation\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, GridSearchCV \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "#pip install scikit-plot \n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Weights for Debate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we need to build a text classification model. We will use techniques learned in class. Note we are going to use all of the speakers in this model not just Trump and Hillary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and format data\n",
    "df5 = pd.read_csv(\"data/debate.csv\", encoding = 'iso-8859-1')\n",
    "del df5['Line']\n",
    "del df5['Date']\n",
    "df7 = df5[df5.Speaker==\"Clinton\"].copy()\n",
    "df8 = df5[df5.Speaker==\"Trump\"].copy()\n",
    "df5= df7.append(df8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are set so Trump = 1 and Clinton = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df5['Speaker'] = df5['Speaker'].str.replace('Trump', '0')\n",
    "df5['Speaker'] = df5['Speaker'].str.replace('Clinton', '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#target_names is a list of the two categories which is a class-label list.\n",
    "target_names = ['Trump', 'Clinton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df5 = df5.rename(columns={'Speaker': 'Label', 'Text': 'Data'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create seperate dataframes for data and labels. \n",
    "sms = df5.copy()\n",
    "sms_data = df5['Data'].copy()\n",
    "sms_labels = df5['Label'].copy()\n",
    "\n",
    "#use .values.tolist() to transform dataframe into list\n",
    "sms = sms.values.tolist()\n",
    "sms_data = sms_data.values.tolist()\n",
    "sms_labels = sms_labels.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 478, 120, 120)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(sms_data, sms_labels, test_size=0.2, random_state=0)\n",
    "len(x_train), len(y_train), len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_train must be an array for this\n",
    "import numpy as np\n",
    "y_train1 = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create vectors\n",
    "vectorizer = TfidfVectorizer(decode_error ='ignore', stop_words='english')\n",
    "tfidf_X = vectorizer.fit_transform(x_train)\n",
    "count_vectorizer = CountVectorizer(vocabulary=vectorizer.vocabulary_, decode_error ='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromScikit(X=count_vectorizer.fit_transform(x_train), \n",
    "                             y=y_train1, \n",
    "                             feature_vocabulary=vectorizer.vocabulary_,\n",
    "                             category_names=target_names,\n",
    "                             raw_texts=x_train).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = CDClassifier(penalty=\"l1/l2\",\n",
    "                   loss=\"squared_hinge\",\n",
    "                   multiclass=True,\n",
    "                   max_iter=20,\n",
    "                   alpha=1e-4,\n",
    "                   C=1.0 / tfidf_X.shape[0],\n",
    "                   tol=1e-3)\n",
    "clf.fit(tfidf_X, y_train1)\n",
    "term_scores = clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nminshew\\Anaconda2\\envs\\py36\\lib\\site-packages\\scattertext\\TermDocMatrix.py:170: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  freq_mat[:, cat_i] = self._X[self._y == cat_i, :].sum(axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "938913"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_frequency_explorer(corpus, 'Clinton', scores=term_scores,\n",
    "                                     use_term_significance=True,\n",
    "                                     terms_to_include=st.AutoTermSelector.get_selected_terms(corpus, term_scores, 4000),\n",
    "                                     metadata = y_train1)\n",
    "open(\"class.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1500\"\n",
       "            height=\"700\"\n",
       "            src=\"class.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1d9b94cab00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "file_name = 'class.html'\n",
    "file = open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1500, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example from Scattertext Git Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightning.classification import CDClassifier\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import scattertext as st\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(\n",
    "\tsubset='train',\n",
    "\tremove=('headers', 'footers', 'quotes')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_X = vectorizer.fit_transform(newsgroups_train.data)\n",
    "count_vectorizer = CountVectorizer(vocabulary=vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromScikit(\n",
    "\tX=count_vectorizer.fit_transform(newsgroups_train.data),\n",
    "\ty=newsgroups_train.target,\n",
    "\tfeature_vocabulary=vectorizer.vocabulary_,\n",
    "\tcategory_names=newsgroups_train.target_names,\n",
    "\traw_texts=newsgroups_train.data\n",
    ").build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = CDClassifier(penalty=\"l1/l2\",\n",
    "                   loss=\"squared_hinge\",\n",
    "                   multiclass=True,\n",
    "                   max_iter=20,\n",
    "                   alpha=1e-4,\n",
    "                   C=1.0 / tfidf_X.shape[0],\n",
    "                   tol=1e-3)\n",
    "clf.fit(tfidf_X, newsgroups_train.target)\n",
    "term_scores = clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16631073"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_frequency_explorer(\n",
    "\tcorpus,\n",
    "\t'alt.atheism',\n",
    "\tscores=term_scores,\n",
    "\tuse_term_significance=False,\n",
    "\tterms_to_include=st.AutoTermSelector.get_selected_terms(corpus, term_scores, 4000),\n",
    "\tmetadata = ['/'.join(fn.split('/')[-2:]) for fn in newsgroups_train.filenames]\n",
    ")\n",
    "\n",
    "open(\"class.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1500\"\n",
       "            height=\"700\"\n",
       "            src=\"class.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1d9c68b3cc0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "file_name = 'class.html'\n",
    "file = open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1500, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
